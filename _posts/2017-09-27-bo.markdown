---
layout: post
title:  "Bayesian Optimisation"
date:   2017-09-17 00:33:14 +0530
categories: Notes, BO, Bayesian Optimisation, Gaussian Process
---

# List of Topics

- What is your understanding?
- Problem Setup
- BO Algorithm
- Aquisition Function
- Gaussian Process

# Problem Setup

- Mutli Arm Bandit Problem:
	- Exploration Exploitation Paradigm
		- Regret = Player Reward - Reward of Best actions
	- Process of evaluation of event is costly
	- Evaluating max f(x)
		- Black Box Evaluations
		- Works even without gradient information. But gradient can help
	- Using feedback (user/evaluations) to remove uncertainity and learning
	- Finds global optimum - function need not be convex
	- Serial process
	- framework is very data efficient
	- Works on Multimodal data too

- Earlier Solutions: 
	- RLS, DIRECT, STAGE, GREEDY

- [Slides](file:///Users/kannappanjayakodinitthilan/Documents/myfolder/project_devan/aws_workspace/source/talks/bo/l7.pdf)

# BO ALgorithm

- Assumptions:
	- Using Gaussian Process [Discuss this later]
	- Successive points are correlated i.e. the functions are smooth
	- Graph:
		- Dotted Line - Actual Function
		- Black line - Model approximation
		- Band - Uncertainity
		- Green - Modeling Uncertainity (Utility)


- Basic Idea:
	- Real world event is approximated as a equivalent model [GP used, RF also work good]
	- Evaluating model is faster compared to actual act
	- Exploration - Exploitation 
		- Know points would have no uncertainity so zero std deviation
		- Unknown points the more further away from know points the larger the std deviation
	- Create a AF (Aquisition Function) - Utility Function which models this Exploration-Exploitation and maximise this
	- Evaluate Objective Function
	- Augument this to the model

# Aquisition Function

- Basic Function 
	- Upper Confdence Bound: Mu(x) + K * sigma(x) 
	- Probability of Improvement
	- Expected Improvement
- PI:
	- Have a current max value (fmax) for the objective
	- Area under the pdf
	- All values below the fmax are ignored.
		- This is explained later in a better slide
	- Adding a small offset so that we do not get the same value again
	- Assuming two values have the same mean, the one with more std deviation is considered
- Expected Improvement
- GP-UCB
- Thompson Sampling:
	- Draw a random function with the known points
	- Then optimise the function to get the max value

# Some Statements
- Why cannot I just find the function where std is very high?
- PI is performing bad but if you know what is the max possible value PI performs much better - Statement

# Why BO works
- For regions where the cureve is lesser than the current maximum, we need not evaluate at all and search only in the region where it matters

# [Show animation](https://github.com/fmfn/BayesianOptimization)


# Gaussian Process
- [Slides](file:///Users/kannappanjayakodinitthilan/Documents/myfolder/project_devan/aws_workspace/source/talks/bo/l6.pdf)

# Applications:
	- Interactive User Interfaces Design - A/B Testing - 
	- Environmental Monitoring - Oil Drilling
	- Combinatorial Optimisation - Finding a desing maximising a objective
	- Automatic Machine Learning - Hyperparameter learning
	- Robotics - Policy learning/Gait learning


# Random Embeddings (REM-BO)
- [Paper Figure 2](https://jair.org/media/4806/live-4806-9131-jair.pdf)
- Problem: Bayesian Optimisation fails when number of parameters to optimise is more than 10-20 (around 25)
	- higher dimensions
- Many researchers have noted that for certain classes of problems most dimensions do not change the objective function significantly
	- ‚Äúlow effective dimensionality‚Äù.
- random search can exploit low effective dimensionality without knowing which dimensions are important.

- BO Setup:
	- Prior [Surrogate model]: Gaussian process
	- AF [Utility Function]: Expected Improvement

- Random Embedding Theorem:
	- Definition of effective dimentionality
	- Theorem 2: Stating there exists a "y" for a random matrix Dxd mapping x to a reduced dimentionality
- REMBO Algorithm:
	- Algorithm 2, Figure 3
	- Theorem 3

- Effectiveness of REMBO:
	- Theorem 3 only guarantees that Y contains the optimum with probability at least 1‚àí; 
- with probability Œ¥ ‚â§  the optimizer lies outside of Y. 
- There are several ways to guard against this problem. One is to simply run REMBO multiple times with different independently
drawn random embeddings. 
- Since the probability of failure with each embedding is Œ¥, the probability of the optimizer not being included in the considered space of k independently drawn embeddings is Œ¥^k
- Thus, the failure probability vanishes exponentially quickly in the number of REMBO runs, k.
- Note also that these independent runs can be trivially parallelized to harness the power of modern multi-core machines and large compute clusters.

- Applications:
	- Synthetic function: 2 to 25,10^9
	- Mixed Linear Programmer ??
	- Kinetic Body Part Classifier:


# Reference
- [Taking the Human Out of the Loop: A Review of Bayesian Optimization](https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf)

- [Bayesian Optimization in a Billion Dimensions via Random Embeddings](https://jair.org/media/4806/live-4806-9131-jair.pdf)

- [Nando Feritas Lectures](http://www.cs.ubc.ca/~nando/540-2013/lectures.html)

- [github](https://github.com/fmfn/BayesianOptimization)

- [Nando Feritas Lectures - new lectures](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)
